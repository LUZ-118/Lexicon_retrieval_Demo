{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLjg-4M5iNqX",
    "outputId": "d580b124-8c02-4f60-aced-9ffbbbb3513e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!\n",
      "Query size:  100  /  Document size:  10000\n",
      "execution time: 0.001000\n"
     ]
    }
   ],
   "source": [
    "# PLSA\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "file_name = \"test_data/2022-ntust-information-retrieval-hw4.zip\"\n",
    "\n",
    "with ZipFile(file_name, 'r',) as zip:\n",
    "    zip.extractall(path = 'test_data/extractHere/2022-ntust-information-retrieval-hw4')\n",
    "    print('Done!!')\n",
    "    All_lst = zip.namelist()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# 建dataset的所有檔名列表\n",
    "Query_lst = []\n",
    "Doc_lst = []\n",
    "\n",
    "for i in All_lst:\n",
    "    if \"documents/\" in i:\n",
    "        Doc_lst.append(i)\n",
    "    elif \"queries/\" in i:\n",
    "        Query_lst.append(i)\n",
    "\n",
    "print(\"Query size: \", len(Query_lst),' / ',\"Document size: \", len(Doc_lst))\n",
    "\n",
    "end = time.time()\n",
    "print(\"execution time: %f\" %(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pJdiEvWyzknj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of terms:  347\n",
      "execution time(all small n): 0.220958\n"
     ]
    }
   ],
   "source": [
    "# 可以在這建立lexicon\n",
    "lexicon = {}\n",
    "data_addr = 'test_data/extractHere/2022-ntust-information-retrieval-hw4/'\n",
    "\n",
    "start = time.time()\n",
    "for i in Query_lst:\n",
    "    file = open(data_addr + i, errors = 'ignore').read().split()\n",
    "    for term in file:\n",
    "        lexicon[term] = 0\n",
    "\n",
    "# 要把document所有字也加進lexicon?\n",
    "# BG_L = 0\n",
    "# for i in Doc_lst:\n",
    "#     file = open(data_addr + i, errors = 'ignore').read().split()\n",
    "#     for term in file:\n",
    "# #         lexicon[term] = 0\n",
    "#         BG_L = BG_L + 1\n",
    "\n",
    "print(\"number of terms: \", len(lexicon))\n",
    "\n",
    "end = time.time()\n",
    "print(\"execution time(all small n): %f\" %(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time(all small n): 37.318604\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "start = time.time()\n",
    "count_in_Q = []\n",
    "for i in Query_lst:\n",
    "    count = lexicon.copy()\n",
    "    file = open(data_addr + i, errors = 'ignore').read().split()\n",
    "    for term in file:\n",
    "        if term in lexicon:\n",
    "            count[term] = count[term] + 1\n",
    "    \n",
    "    count_in_Q.append(list(count.values()))\n",
    "\n",
    "count_in_Q = np.array(count_in_Q)\n",
    "\n",
    "count_in_D = []\n",
    "for i in Doc_lst:\n",
    "    count = lexicon.copy()\n",
    "    file = open(data_addr + i, errors = 'ignore').read().split()\n",
    "    for term in file:\n",
    "        if term in lexicon:\n",
    "            count[term] = count[term] + 1\n",
    "    \n",
    "    count_in_D.append(list(count.values()))\n",
    "\n",
    "count_in_D = np.array(count_in_D)\n",
    "end = time.time()\n",
    "print(\"execution time(all small n): %f\" %(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_in_Q length:  100\n",
      "count_in_D length:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"count_in_Q length: \", len(count_in_Q))\n",
    "print(\"count_in_D length: \", len(count_in_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import time\n",
    "\n",
    "@jit()\n",
    "def Likelyhood(V, D, count):\n",
    "    L = 0.0\n",
    "    for wi in range(V):\n",
    "        for dj in range(D):\n",
    "            L = L* np.power(count[dj, wi]/ (np.sum(count[dj])+1), count[dj, wi])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def EM_step(curr_P_wT, curr_P_Td, prev_P_wT, prev_P_Td, P_Tkwd_tmp, count, V, D, K):\n",
    "    ######\n",
    "    for wi in range(V):\n",
    "        for dj in range(D):\n",
    "            P_Tkwd_tmp = np.multiply(prev_P_wT[wi], prev_P_Td.T[dj])\n",
    "            if np.sum(P_Tkwd_tmp) == 0:\n",
    "                continue\n",
    "            P_Tkwd_tmp = P_Tkwd_tmp / np.sum(P_Tkwd_tmp)               \n",
    "            curr_P_wT[wi] = curr_P_wT[wi] + count[dj, wi]* P_Tkwd_tmp\n",
    "    sum_1 = np.sum(curr_P_wT, axis = 0)\n",
    "    for Tk in range(K):\n",
    "        if sum_1[Tk] == 0.0:\n",
    "            continue\n",
    "        curr_P_wT.T[Tk] = curr_P_wT.T[Tk]/sum_1[Tk]\n",
    "    \n",
    "    ######\n",
    "    for dj in range(D):\n",
    "        for wi in range(V):\n",
    "            P_Tkwd_tmp = np.multiply(prev_P_Td.T[dj], prev_P_wT[wi])\n",
    "            if np.sum(P_Tkwd_tmp) == 0:\n",
    "                continue\n",
    "            P_Tkwd_tmp = P_Tkwd_tmp / np.sum(P_Tkwd_tmp)\n",
    "            curr_P_Td.T[dj] = curr_P_Td.T[dj] + count[dj][wi]* P_Tkwd_tmp\n",
    "    \n",
    "    for dj in range(D):\n",
    "        curr_P_Td.T[dj] = curr_P_Td.T[dj]/np.sum(count[dj])\n",
    "    \n",
    "    return curr_P_wT, curr_P_Td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLSA(max_iter, curr_P_wT, curr_P_Td, P_Tkwd_tmp, count, V, D, K):\n",
    "    print(\"Training.....\")\n",
    "    for iteration in range(max_iter):\n",
    "        start = time.time()\n",
    "        P_Tkwd_tmp = np.zeros(LT, dtype = np.float64)\n",
    "        prev_P_wT = np.copy(curr_P_wT)\n",
    "        prev_P_Td = np.copy(curr_P_Td)\n",
    "        \n",
    "#         L = Likelyhood(V, D, count)\n",
    "#         print(\"\\nLikelyhood: \", L)\n",
    "    \n",
    "        curr_P_wT = np.zeros([V, K], dtype = np.float64)\n",
    "        curr_P_Td = np.zeros([K, D], dtype = np.float64)\n",
    "        curr_P_wT, curr_P_Td = EM_step(curr_P_wT, curr_P_Td, prev_P_wT, prev_P_Td, P_Tkwd_tmp, count, V, D, K)\n",
    "        \n",
    "        print(\"Iteration: \", iteration + 1, \"-------time cost: \", round(time.time()-start, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.....\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  1 -------time cost:  5.509\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  2 -------time cost:  3.03\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  3 -------time cost:  3.025\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  4 -------time cost:  2.991\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  5 -------time cost:  2.995\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  6 -------time cost:  2.961\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  7 -------time cost:  2.875\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  8 -------time cost:  2.797\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  9 -------time cost:  2.891\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  10 -------time cost:  2.792\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  11 -------time cost:  2.756\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  12 -------time cost:  2.882\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  13 -------time cost:  2.801\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  14 -------time cost:  2.793\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  15 -------time cost:  2.796\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  16 -------time cost:  2.791\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  17 -------time cost:  2.795\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  18 -------time cost:  2.825\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  19 -------time cost:  2.895\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  20 -------time cost:  2.891\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  21 -------time cost:  2.865\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  22 -------time cost:  2.796\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  23 -------time cost:  2.752\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  24 -------time cost:  2.877\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  25 -------time cost:  2.795\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  26 -------time cost:  2.803\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  27 -------time cost:  2.805\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  28 -------time cost:  2.726\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  29 -------time cost:  2.753\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  30 -------time cost:  2.817\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  31 -------time cost:  2.812\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  32 -------time cost:  2.729\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  33 -------time cost:  2.805\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  34 -------time cost:  2.76\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  35 -------time cost:  2.803\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  36 -------time cost:  2.812\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  37 -------time cost:  2.703\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  38 -------time cost:  2.75\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  39 -------time cost:  2.799\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  40 -------time cost:  2.839\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  41 -------time cost:  2.773\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  42 -------time cost:  2.756\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  43 -------time cost:  2.947\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  44 -------time cost:  2.965\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  45 -------time cost:  2.969\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  46 -------time cost:  2.936\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  47 -------time cost:  2.82\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  48 -------time cost:  2.823\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  49 -------time cost:  2.803\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  50 -------time cost:  2.82\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  51 -------time cost:  2.803\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  52 -------time cost:  2.874\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  53 -------time cost:  2.821\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  54 -------time cost:  2.791\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  55 -------time cost:  2.839\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  56 -------time cost:  2.818\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  57 -------time cost:  2.787\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  58 -------time cost:  2.818\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  59 -------time cost:  2.796\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  60 -------time cost:  2.805\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  61 -------time cost:  2.824\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  62 -------time cost:  2.847\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  63 -------time cost:  2.82\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  64 -------time cost:  2.832\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  65 -------time cost:  2.834\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  66 -------time cost:  2.774\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  67 -------time cost:  2.782\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  68 -------time cost:  2.811\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  69 -------time cost:  2.872\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  70 -------time cost:  2.818\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  71 -------time cost:  2.833\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  72 -------time cost:  2.92\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  73 -------time cost:  2.91\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  74 -------time cost:  2.83\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  75 -------time cost:  2.831\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  76 -------time cost:  2.808\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  77 -------time cost:  2.788\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  78 -------time cost:  2.849\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  79 -------time cost:  2.81\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  80 -------time cost:  2.797\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  81 -------time cost:  2.827\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  82 -------time cost:  2.83\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  83 -------time cost:  2.817\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  84 -------time cost:  3.051\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  85 -------time cost:  2.777\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  86 -------time cost:  2.822\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  87 -------time cost:  2.888\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  88 -------time cost:  2.758\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  89 -------time cost:  2.935\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  90 -------time cost:  2.849\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  91 -------time cost:  2.799\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  92 -------time cost:  2.844\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  93 -------time cost:  2.826\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  94 -------time cost:  2.859\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  95 -------time cost:  3.031\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  96 -------time cost:  2.812\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  97 -------time cost:  2.78\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  98 -------time cost:  2.802\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  99 -------time cost:  2.849\n",
      "\n",
      "Likelyhood:  0.0\n",
      "Iteration:  100 -------time cost:  2.964\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# latent_Topics\n",
    "# initialize\n",
    "LT = 30\n",
    "max_iter = 70\n",
    "absV = len(lexicon)\n",
    "absD = len(Doc_lst)\n",
    "\n",
    "BG_L = np.sum(count_in_D)\n",
    "count_in_BG = np.sum(count_in_D, axis=0)\n",
    "\n",
    "P_Tkwd = np.zeros(LT, dtype = np.float64)\n",
    "P_wT = np.random.random([absV, LT])\n",
    "P_wT = P_wT / np.sum(P_wT)\n",
    "P_Td = np.random.random([LT, absD])\n",
    "P_Td = P_Td / np.sum(P_Td)\n",
    "\n",
    "PLSA(max_iter, P_wT, P_Td, P_Tkwd, count_in_D, absV, absD, LT)\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def SIM_CAL(D, V, count_in_Q, count_in_D, P_wT, P_Td ,ans, Alpha, Beta, count_in_BG, BG_L, sim_list):\n",
    "    for dj in range(D):\n",
    "        for wi in range(V):\n",
    "            if count_in_Q[ans, wi] == 0:\n",
    "                continue\n",
    "\n",
    "            sum_1 = np.sum(np.multiply(P_wT[wi], P_Td.T[dj]))\n",
    "\n",
    "            prob1 = np.log(Alpha) + np.log(count_in_D[dj, wi]/(np.sum(count_in_D[dj])+1))\n",
    "            prob2 = np.log(Beta) + np.log(sum_1)\n",
    "            prob3 = np.log(1-Alpha-Beta) + np.log(count_in_BG[wi]/(BG_L+1))\n",
    "            prob123 = np.logaddexp(np.logaddexp(prob1, prob2), prob3)\n",
    "\n",
    "            sim_list[dj] = sim_list[dj] + prob123\n",
    "    return sim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time: 3.395604\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import winsound\n",
    "import time\n",
    "import math\n",
    "\n",
    "start = time.time()\n",
    "# 每一迴圈輸出一個Query的結果到test.csv\n",
    "with open(\"test_data/test.csv\", \"w\", newline='') as Answer_csv:\n",
    "    Answer_csv.truncate()\n",
    "    writer = csv.writer(Answer_csv)\n",
    "    writer.writerow(['Query', 'RetrievedDocuments'])\n",
    "    \n",
    "    for ans in range(len(Query_lst)):\n",
    "        Alpha = 0.1\n",
    "        Beta = 0.1\n",
    "        \n",
    "        sim_list = np.zeros(len(Doc_lst))\n",
    "        \n",
    "        sim_list = SIM_CAL(len(Doc_lst), len(lexicon), count_in_Q, count_in_D, P_wT, P_Td ,ans, Alpha, Beta, count_in_BG, BG_L, sim_list)\n",
    "        \n",
    "        sorted_Doc = sorted(range(len(sim_list)), key=lambda k: sim_list[k], reverse = True)\n",
    "\n",
    "        ans_str = Doc_lst[sorted_Doc[0]].replace('documents/', '').replace(\".txt\", '')\n",
    "        #MAP3000\n",
    "        for i in range(1, 3000): \n",
    "            ans_str = ans_str + ' ' + Doc_lst[sorted_Doc[i]].replace('documents/', '').replace(\".txt\", '')\n",
    "        \n",
    "        writer.writerow([Query_lst[ans].replace('queries/', '').replace(\".txt\", '')] + [ans_str])\n",
    "\n",
    "end = time.time()\n",
    "print(\"execution time: %f\" %(end - start))\n",
    "\n",
    "duration = 500  # millisecond\n",
    "freq = 440  # Hz\n",
    "for i in range(5):\n",
    "    winsound.Beep(freq, duration)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
